# 08_production_deployment.py - ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²èˆ‡ç›£æ§
import os
import logging
import time
from dotenv import load_dotenv
from llama_index.core import (
    VectorStoreIndex, 
    SimpleDirectoryReader,
    Settings,
    StorageContext
)
from llama_index.core.node_parser import SentenceSplitter
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
import chromadb
from typing import Dict, List, Any

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('llamaindex_production.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ProductionRAGSystem:
    """ç”Ÿç”¢ç’°å¢ƒ RAG ç³»çµ±"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–ç”Ÿç”¢ç’°å¢ƒç³»çµ±"""
        self.config = config
        self.index = None
        self.query_engine = None
        self.metrics = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "average_response_time": 0.0
        }
        
        logger.info("åˆå§‹åŒ–ç”Ÿç”¢ç’°å¢ƒ RAG ç³»çµ±...")
        self._setup_system()
    
    def _setup_system(self):
        """è¨­å®šç³»çµ±çµ„ä»¶"""
        try:
            # è¨­å®šåµŒå…¥æ¨¡å‹
            embed_model = OpenAIEmbedding(
                model=self.config.get("embedding_model", "text-embedding-3-small"),
                embed_batch_size=self.config.get("embed_batch_size", 10)
            )
            Settings.embed_model = embed_model
            
            # è¨­å®šç¯€é»è§£æå™¨
            node_parser = SentenceSplitter(
                chunk_size=self.config.get("chunk_size", 1024),
                chunk_overlap=self.config.get("chunk_overlap", 200)
            )
            
            # è¼‰å…¥æ–‡ä»¶
            documents = self._load_documents()
            
            # å»ºç«‹ç´¢å¼•
            self.index = self._create_index(documents, node_parser)
            
            # å»ºç«‹æŸ¥è©¢å¼•æ“
            self.query_engine = self._create_query_engine()
            
            logger.info("ç³»çµ±è¨­å®šå®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç³»çµ±è¨­å®šå¤±æ•—: {e}")
            raise
    
    def _load_documents(self):
        """è¼‰å…¥æ–‡ä»¶"""
        documents_dir = self.config.get("documents_dir", "sample_documents")
        
        if not os.path.exists(documents_dir):
            logger.warning(f"æ–‡ä»¶ç›®éŒ„ä¸å­˜åœ¨: {documents_dir}")
            return []
        
        reader = SimpleDirectoryReader(input_dir=documents_dir)
        documents = reader.load_data()
        
        logger.info(f"è¼‰å…¥äº† {len(documents)} å€‹æ–‡ä»¶")
        return documents
    
    def _create_index(self, documents, node_parser):
        """å»ºç«‹ç´¢å¼•"""
        if self.config.get("use_chroma", False):
            return self._create_chroma_index(documents, node_parser)
        else:
            return self._create_simple_index(documents, node_parser)
    
    def _create_simple_index(self, documents, node_parser):
        """å»ºç«‹ç°¡å–®ç´¢å¼•"""
        index = VectorStoreIndex.from_documents(
            documents,
            transformations=[node_parser]
        )
        logger.info("ç°¡å–®ç´¢å¼•å»ºç«‹å®Œæˆ")
        return index
    
    def _create_chroma_index(self, documents, node_parser):
        """å»ºç«‹ ChromaDB ç´¢å¼•"""
        try:
            # åˆå§‹åŒ– ChromaDB
            chroma_client = chromadb.PersistentClient(
                path=self.config.get("chroma_path", "./chroma_production")
            )
            
            collection = chroma_client.get_or_create_collection(
                name=self.config.get("collection_name", "production_kb"),
                metadata={"description": "ç”Ÿç”¢ç’°å¢ƒçŸ¥è­˜åº«"}
            )
            
            # å»ºç«‹å‘é‡å„²å­˜
            vector_store = ChromaVectorStore(chroma_collection=collection)
            storage_context = StorageContext.from_defaults(vector_store=vector_store)
            
            # å»ºç«‹ç´¢å¼•
            index = VectorStoreIndex.from_documents(
                documents,
                storage_context=storage_context,
                transformations=[node_parser]
            )
            
            logger.info(f"ChromaDB ç´¢å¼•å»ºç«‹å®Œæˆï¼Œé›†åˆ: {collection.name}")
            return index
            
        except Exception as e:
            logger.error(f"ChromaDB ç´¢å¼•å»ºç«‹å¤±æ•—: {e}")
            return self._create_simple_index(documents, node_parser)
    
    def _create_query_engine(self):
        """å»ºç«‹æŸ¥è©¢å¼•æ“"""
        query_engine = self.index.as_query_engine(
            similarity_top_k=self.config.get("similarity_top_k", 3),
            response_mode=self.config.get("response_mode", "compact"),
            streaming=self.config.get("streaming", False)
        )
        
        logger.info("æŸ¥è©¢å¼•æ“å»ºç«‹å®Œæˆ")
        return query_engine
    
    def query(self, question: str) -> Dict[str, Any]:
        """åŸ·è¡ŒæŸ¥è©¢"""
        start_time = time.time()
        self.metrics["total_queries"] += 1
        
        try:
            logger.info(f"åŸ·è¡ŒæŸ¥è©¢: {question}")
            
            response = self.query_engine.query(question)
            
            end_time = time.time()
            response_time = end_time - start_time
            
            # æ›´æ–°æŒ‡æ¨™
            self.metrics["successful_queries"] += 1
            self._update_average_response_time(response_time)
            
            result = {
                "success": True,
                "response": response.response,
                "response_time": response_time,
                "source_nodes": len(response.source_nodes),
                "timestamp": time.time()
            }
            
            logger.info(f"æŸ¥è©¢æˆåŠŸï¼Œå›æ‡‰æ™‚é–“: {response_time:.2f}ç§’")
            return result
            
        except Exception as e:
            end_time = time.time()
            response_time = end_time - start_time
            
            self.metrics["failed_queries"] += 1
            logger.error(f"æŸ¥è©¢å¤±æ•—: {e}")
            
            return {
                "success": False,
                "error": str(e),
                "response_time": response_time,
                "timestamp": time.time()
            }
    
    def _update_average_response_time(self, response_time: float):
        """æ›´æ–°å¹³å‡å›æ‡‰æ™‚é–“"""
        total_successful = self.metrics["successful_queries"]
        current_avg = self.metrics["average_response_time"]
        
        # è¨ˆç®—æ–°çš„å¹³å‡å€¼
        new_avg = ((current_avg * (total_successful - 1)) + response_time) / total_successful
        self.metrics["average_response_time"] = new_avg
    
    def get_metrics(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±æŒ‡æ¨™"""
        success_rate = 0
        if self.metrics["total_queries"] > 0:
            success_rate = self.metrics["successful_queries"] / self.metrics["total_queries"]
        
        return {
            **self.metrics,
            "success_rate": success_rate,
            "system_status": "healthy" if success_rate > 0.9 else "degraded"
        }
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æª¢æŸ¥"""
        try:
            # åŸ·è¡Œç°¡å–®æŸ¥è©¢æ¸¬è©¦
            test_result = self.query("æ¸¬è©¦æŸ¥è©¢")
            
            return {
                "status": "healthy" if test_result["success"] else "unhealthy",
                "response_time": test_result.get("response_time", 0),
                "timestamp": time.time()
            }
            
        except Exception as e:
            logger.error(f"å¥åº·æª¢æŸ¥å¤±æ•—: {e}")
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": time.time()
            }

def demonstrate_production_setup():
    """ç¤ºç¯„ç”Ÿç”¢ç’°å¢ƒè¨­å®š"""
    print("ğŸ­ ç”Ÿç”¢ç’°å¢ƒè¨­å®šç¤ºç¯„...")
    
    # ç”Ÿç”¢ç’°å¢ƒé…ç½®
    production_config = {
        "embedding_model": "text-embedding-3-small",
        "embed_batch_size": 10,
        "chunk_size": 1024,
        "chunk_overlap": 200,
        "similarity_top_k": 3,
        "response_mode": "compact",
        "streaming": False,
        "use_chroma": True,
        "chroma_path": "./chroma_production",
        "collection_name": "production_kb",
        "documents_dir": "sample_documents"
    }
    
    # å»ºç«‹ç”Ÿç”¢ç’°å¢ƒç³»çµ±
    rag_system = ProductionRAGSystem(production_config)
    
    return rag_system

def demonstrate_monitoring(rag_system):
    """ç¤ºç¯„ç›£æ§åŠŸèƒ½"""
    print("\nğŸ“Š ç›£æ§åŠŸèƒ½ç¤ºç¯„...")
    
    # åŸ·è¡Œæ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯äººå·¥æ™ºæ…§ï¼Ÿ",
        "é›²ç«¯é‹ç®—çš„å„ªå‹¢æœ‰å“ªäº›ï¼Ÿ",
        "æ©Ÿå™¨å­¸ç¿’å’Œæ·±åº¦å­¸ç¿’çš„å·®ç•°ï¼Ÿ"
    ]
    
    for query in test_queries:
        print(f"\næ¸¬è©¦æŸ¥è©¢: {query}")
        result = rag_system.query(query)
        
        if result["success"]:
            print(f"âœ… æŸ¥è©¢æˆåŠŸ")
            print(f"   å›æ‡‰æ™‚é–“: {result['response_time']:.2f}ç§’")
            print(f"   ä¾†æºç¯€é»: {result['source_nodes']}å€‹")
            print(f"   å›æ‡‰: {result['response'][:100]}...")
        else:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {result['error']}")
    
    # é¡¯ç¤ºç³»çµ±æŒ‡æ¨™
    print(f"\nğŸ“ˆ ç³»çµ±æŒ‡æ¨™:")
    metrics = rag_system.get_metrics()
    for key, value in metrics.items():
        print(f"   {key}: {value}")
    
    # å¥åº·æª¢æŸ¥
    print(f"\nğŸ¥ å¥åº·æª¢æŸ¥:")
    health = rag_system.health_check()
    print(f"   ç‹€æ…‹: {health['status']}")
    print(f"   å›æ‡‰æ™‚é–“: {health.get('response_time', 0):.2f}ç§’")

def demonstrate_error_handling():
    """ç¤ºç¯„éŒ¯èª¤è™•ç†"""
    print("\nğŸ›¡ï¸ éŒ¯èª¤è™•ç†ç¤ºç¯„...")
    
    # å»ºç«‹ç³»çµ±
    config = {
        "documents_dir": "sample_documents",
        "use_chroma": False
    }
    
    rag_system = ProductionRAGSystem(config)
    
    # æ¸¬è©¦å„ç¨®éŒ¯èª¤æƒ…æ³
    error_tests = [
        "",  # ç©ºæŸ¥è©¢
        "a" * 10000,  # éé•·æŸ¥è©¢
        "æ¸¬è©¦æŸ¥è©¢" * 100,  # é‡è¤‡æŸ¥è©¢
    ]
    
    for i, test_query in enumerate(error_tests, 1):
        print(f"\néŒ¯èª¤æ¸¬è©¦ {i}: {test_query[:50]}...")
        result = rag_system.query(test_query)
        
        if result["success"]:
            print(f"âœ… è™•ç†æˆåŠŸ")
        else:
            print(f"âŒ è™•ç†å¤±æ•—: {result['error']}")

def demonstrate_scalability():
    """ç¤ºç¯„å¯æ“´å±•æ€§"""
    print("\nğŸ“ˆ å¯æ“´å±•æ€§ç¤ºç¯„...")
    
    # å»ºç«‹ç³»çµ±
    config = {
        "documents_dir": "sample_documents",
        "use_chroma": True,
        "chroma_path": "./chroma_scalable"
    }
    
    rag_system = ProductionRAGSystem(config)
    
    # ä¸¦è¡ŒæŸ¥è©¢æ¸¬è©¦
    import concurrent.futures
    import threading
    
    def query_worker(query_id):
        """æŸ¥è©¢å·¥ä½œå‡½æ•¸"""
        query = f"æ¸¬è©¦æŸ¥è©¢ {query_id}"
        result = rag_system.query(query)
        return result
    
    # åŸ·è¡Œä¸¦è¡ŒæŸ¥è©¢
    print("åŸ·è¡Œä¸¦è¡ŒæŸ¥è©¢æ¸¬è©¦...")
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(query_worker, i) for i in range(10)]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    end_time = time.time()
    total_time = end_time - start_time
    
    successful_queries = sum(1 for r in results if r["success"])
    
    print(f"ä¸¦è¡ŒæŸ¥è©¢çµæœ:")
    print(f"   ç¸½æŸ¥è©¢æ•¸: {len(results)}")
    print(f"   æˆåŠŸæŸ¥è©¢æ•¸: {successful_queries}")
    print(f"   ç¸½æ™‚é–“: {total_time:.2f}ç§’")
    print(f"   å¹³å‡æ™‚é–“: {total_time/len(results):.2f}ç§’/æŸ¥è©¢")

def explain_production_considerations():
    """è§£é‡‹ç”Ÿç”¢ç’°å¢ƒè€ƒé‡"""
    print("\nğŸ“š ç”Ÿç”¢ç’°å¢ƒè€ƒé‡:")
    print("""
    1. ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆ
       - å¾®æœå‹™æ¶æ§‹
       - è² è¼‰å‡è¡¡
       - å®¹éŒ¯æ©Ÿåˆ¶
       - æ°´å¹³æ“´å±•
    
    2. ğŸ’¾ è³‡æ–™ç®¡ç†
       - å‘é‡è³‡æ–™åº«é¸æ“‡
       - è³‡æ–™å‚™ä»½ç­–ç•¥
       - ç´¢å¼•æ›´æ–°æ©Ÿåˆ¶
       - è³‡æ–™ä¸€è‡´æ€§
    
    3. ğŸ”’ å®‰å…¨æ€§
       - API èªè­‰æˆæ¬Š
       - è³‡æ–™åŠ å¯†
       - è¼¸å…¥é©—è­‰
       - å­˜å–æ§åˆ¶
    
    4. ğŸ“Š ç›£æ§èˆ‡æ—¥èªŒ
       - æ•ˆèƒ½æŒ‡æ¨™è¿½è¹¤
       - éŒ¯èª¤æ—¥èªŒè¨˜éŒ„
       - å¥åº·æª¢æŸ¥æ©Ÿåˆ¶
       - å‘Šè­¦ç³»çµ±
    
    5. âš¡ æ•ˆèƒ½å„ªåŒ–
       - å¿«å–ç­–ç•¥
       - æŸ¥è©¢å„ªåŒ–
       - è³‡æºç®¡ç†
       - ä¸¦è¡Œè™•ç†
    
    6. ğŸ”„ éƒ¨ç½²èˆ‡ç¶­è­·
       - å®¹å™¨åŒ–éƒ¨ç½²
       - è‡ªå‹•åŒ–éƒ¨ç½²
       - ç‰ˆæœ¬ç®¡ç†
       - å›æ»¾æ©Ÿåˆ¶
    
    7. ğŸ“ˆ æ“´å±•æ€§
       - æ°´å¹³æ“´å±•
       - å‚ç›´æ“´å±•
       - è² è¼‰åˆ†æ•£
       - è³‡æºèª¿åº¦
    """)

def demonstrate_best_practices():
    """ç¤ºç¯„æœ€ä½³å¯¦è¸"""
    print("\nâœ¨ æœ€ä½³å¯¦è¸ç¤ºç¯„...")
    
    # æœ€ä½³å¯¦è¸é…ç½®
    best_practices_config = {
        "embedding_model": "text-embedding-3-small",
        "embed_batch_size": 20,  # è¼ƒå¤§çš„æ‰¹æ¬¡å¤§å°
        "chunk_size": 1024,
        "chunk_overlap": 200,
        "similarity_top_k": 5,  # æ›´å¤šçš„æª¢ç´¢çµæœ
        "response_mode": "compact",
        "streaming": True,  # å•Ÿç”¨ä¸²æµ
        "use_chroma": True,
        "chroma_path": "./chroma_best_practices",
        "collection_name": "best_practices_kb",
        "documents_dir": "sample_documents"
    }
    
    # å»ºç«‹æœ€ä½³å¯¦è¸ç³»çµ±
    rag_system = ProductionRAGSystem(best_practices_config)
    
    # æ¸¬è©¦æŸ¥è©¢
    query = "è«‹è©³ç´°èªªæ˜äººå·¥æ™ºæ…§çš„ç™¼å±•è¶¨å‹¢å’Œæœªä¾†å±•æœ›"
    print(f"æŸ¥è©¢: {query}")
    
    result = rag_system.query(query)
    
    if result["success"]:
        print(f"âœ… æŸ¥è©¢æˆåŠŸ")
        print(f"   å›æ‡‰æ™‚é–“: {result['response_time']:.2f}ç§’")
        print(f"   å›æ‡‰é•·åº¦: {len(result['response'])}å­—å…ƒ")
        print(f"   ä¾†æºç¯€é»: {result['source_nodes']}å€‹")
    else:
        print(f"âŒ æŸ¥è©¢å¤±æ•—: {result['error']}")

if __name__ == "__main__":
    try:
        print("ğŸš€ é–‹å§‹å­¸ç¿’ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²...")
        
        # è§£é‡‹ç”Ÿç”¢ç’°å¢ƒè€ƒé‡
        explain_production_considerations()
        
        # ç¤ºç¯„ç”Ÿç”¢ç’°å¢ƒè¨­å®š
        rag_system = demonstrate_production_setup()
        
        # ç¤ºç¯„ç›£æ§åŠŸèƒ½
        demonstrate_monitoring(rag_system)
        
        # ç¤ºç¯„éŒ¯èª¤è™•ç†
        demonstrate_error_handling()
        
        # ç¤ºç¯„å¯æ“´å±•æ€§
        demonstrate_scalability()
        
        # ç¤ºç¯„æœ€ä½³å¯¦è¸
        demonstrate_best_practices()
        
        print("\nğŸ‰ ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²å­¸ç¿’å®Œæˆï¼")
        print("æ­å–œï¼æ‚¨å·²ç¶“å®Œæˆäº†å®Œæ•´çš„ LlamaIndex å­¸ç¿’è·¯å¾‘ï¼")
        
    except Exception as e:
        logger.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()